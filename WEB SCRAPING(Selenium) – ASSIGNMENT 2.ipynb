{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f8f2c4",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d8841",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "77d4b47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74a4dac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_field_dsignation=driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_dsignation.send_keys(\"Data Analyst\")\n",
    "search_field_location=driver.find_element_by_xpath(\"//*[@id='root']/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "search_button=driver.find_element_by_class_name(\"qsbSubmit\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "60a1d547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sr Domain Expert -Data Analysts</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Siemens</td>\n",
       "      <td>0-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Staff Business Data Analyst - FDP</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Intuit Inc.</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Vedantu Innovations</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst 2</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Professional Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>DXC Technology</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MDM - Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Shell</td>\n",
       "      <td>3-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Opening For Data Analyst ll Bangalore ll Unaca...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Unacademy</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst - Sales Analytics (Remote)</td>\n",
       "      <td>Remote</td>\n",
       "      <td>AIRMEET NETWORKS PRIVATE LIMITED</td>\n",
       "      <td>4-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Thomson Reuters</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title         Job Location  \\\n",
       "0                    Sr Domain Expert -Data Analysts  Bangalore/Bengaluru   \n",
       "1                  Staff Business Data Analyst - FDP  Bangalore/Bengaluru   \n",
       "2                                       Data Analyst  Bangalore/Bengaluru   \n",
       "3                                     Data Analyst 2  Bangalore/Bengaluru   \n",
       "4                                Senior Data Analyst  Bangalore/Bengaluru   \n",
       "5                   Senior Professional Data Analyst  Bangalore/Bengaluru   \n",
       "6                                 MDM - Data Analyst  Bangalore/Bengaluru   \n",
       "7  Opening For Data Analyst ll Bangalore ll Unaca...  Bangalore/Bengaluru   \n",
       "8     Senior Data Analyst - Sales Analytics (Remote)               Remote   \n",
       "9                                Senior Data Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "                       Company Name Experience Required  \n",
       "0                           Siemens            0-10 Yrs  \n",
       "1                       Intuit Inc.             5-7 Yrs  \n",
       "2               Vedantu Innovations             0-3 Yrs  \n",
       "3                            PayPal             5-8 Yrs  \n",
       "4                          Flipkart             3-6 Yrs  \n",
       "5                    DXC Technology             3-7 Yrs  \n",
       "6                             Shell             3-4 Yrs  \n",
       "7                         Unacademy             2-7 Yrs  \n",
       "8  AIRMEET NETWORKS PRIVATE LIMITED             4-5 Yrs  \n",
       "9                   Thomson Reuters             3-8 Yrs  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "compay_names=[]\n",
    "experience_list=[]\n",
    "location_list=[]\n",
    "\n",
    "job_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in job_tags:\n",
    "    job_title=i.text\n",
    "    job_titles.append(job_title)\n",
    "job_titles=job_titles[:10]\n",
    "\n",
    "cmpany_tag=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in cmpany_tag:\n",
    "    company_name=i.text\n",
    "    compay_names.append(company_name)\n",
    "compay_names=compay_names[:10]\n",
    "\n",
    "experience_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tag:\n",
    "    exp = i.text\n",
    "    experience_list.append(exp)\n",
    "experience_list=experience_list[:10]\n",
    "\n",
    "location_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "for i in location_tag:\n",
    "    loc=i.text\n",
    "    location_list.append(loc)\n",
    "location_list=location_list[:10]\n",
    "\n",
    "df1 = pd.DataFrame({\"Job Title\":job_titles,\"Job Location\":location_list,\"Company Name\":compay_names,\"Experience Required\":experience_list})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c6a0e5",
   "metadata": {},
   "source": [
    "### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20dd46",
   "metadata": {},
   "source": [
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eb77050",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "time.sleep(2)\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_field_dsignation=driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_dsignation.send_keys(\"Data Scientist\")\n",
    "search_field_location=driver.find_element_by_xpath(\"//*[@id='root']/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "search_button=driver.find_element_by_class_name(\"qsbSubmit\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "802a86be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>GSK India</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DATA Scientist with Fraud Analytics Experience</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Concentrix</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Meesho</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Zoom Start India</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Rakuten, Inc.</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist Opportunity with PayU ( Tier1 i...</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>PayU</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist 1</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>PayPal</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Developer Associate - Data Scientist(1-3Y)</td>\n",
       "      <td>Bangalore/Bengaluru, Bengaluru/Bangalore</td>\n",
       "      <td>SAP India Pvt.Ltd</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Apptio INC</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                              Senior Data Scientist   \n",
       "1                              Senior Data Scientist   \n",
       "2     DATA Scientist with Fraud Analytics Experience   \n",
       "3                           Principal Data Scientist   \n",
       "4                              Senior Data Scientist   \n",
       "5                           Principal Data Scientist   \n",
       "6  Data Scientist Opportunity with PayU ( Tier1 i...   \n",
       "7                                   Data Scientist 1   \n",
       "8         Developer Associate - Data Scientist(1-3Y)   \n",
       "9                                     Data Scientist   \n",
       "\n",
       "                                        Job Location       Company Name  \\\n",
       "0                                Bangalore/Bengaluru           Flipkart   \n",
       "1                                Bangalore/Bengaluru          GSK India   \n",
       "2                                Bangalore/Bengaluru         Concentrix   \n",
       "3                                Bangalore/Bengaluru             Meesho   \n",
       "4                                Bangalore/Bengaluru   Zoom Start India   \n",
       "5                                Bangalore/Bengaluru      Rakuten, Inc.   \n",
       "6  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...               PayU   \n",
       "7                                Bangalore/Bengaluru             PayPal   \n",
       "8           Bangalore/Bengaluru, Bengaluru/Bangalore  SAP India Pvt.Ltd   \n",
       "9                                Bangalore/Bengaluru         Apptio INC   \n",
       "\n",
       "  Experience Required  \n",
       "0             5-8 Yrs  \n",
       "1             5-9 Yrs  \n",
       "2             2-4 Yrs  \n",
       "3            6-10 Yrs  \n",
       "4             3-6 Yrs  \n",
       "5            7-12 Yrs  \n",
       "6             2-5 Yrs  \n",
       "7             4-8 Yrs  \n",
       "8             5-9 Yrs  \n",
       "9             1-3 Yrs  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles=[]\n",
    "compay_names=[]\n",
    "experience_list=[]\n",
    "location_list=[]\n",
    "\n",
    "job_tags=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in job_tags:\n",
    "    job_title=i.text\n",
    "    job_titles.append(job_title)\n",
    "job_titles=job_titles[:10]\n",
    "\n",
    "cmpany_tag=driver.find_elements_by_xpath(\"//a[@class='subTitle ellipsis fleft']\")\n",
    "for i in cmpany_tag:\n",
    "    company_name=i.text\n",
    "    compay_names.append(company_name)\n",
    "compay_names=compay_names[:10]\n",
    "\n",
    "experience_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']\")\n",
    "for i in experience_tag:\n",
    "    exp = i.text\n",
    "    experience_list.append(exp)\n",
    "experience_list=experience_list[:10]\n",
    "\n",
    "location_tag=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']//span\")\n",
    "for i in location_tag:\n",
    "    loc=i.text\n",
    "    location_list.append(loc)\n",
    "location_list=location_list[:10]\n",
    "\n",
    "df1 = pd.DataFrame({\"Job Title\":job_titles,\"Job Location\":location_list,\"Company Name\":compay_names,\"Experience Required\":experience_list})\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fbbcfd",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "### You have to use the location and salary filter.\n",
    "### You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "### You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ced6b7",
   "metadata": {},
   "source": [
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "deecd36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"219ecf1a4d8482b1b6acab2a3055a718\", element=\"9ceb7094-6751-4911-8df0-751d4382fc91\")>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.get(\"https://www.naukri.com/\")\n",
    "search_field_dsignation=driver.find_element_by_class_name(\"suggestor-input \")\n",
    "search_field_dsignation.send_keys(\"Data Scientist\")\n",
    "search_field_location=driver.find_element_by_xpath(\"//*[@id='root']/div[2]/div[3]/div/div/div[3]/div/div/div/input\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "search_button=driver.find_element_by_class_name(\"qsbSubmit\")\n",
    "search_button.click()\n",
    "time.sleep(10)\n",
    "\n",
    "filter_salary=driver.find_element_by_xpath(\"//input[@id='chk-3-6 Lakhs-ctcFilter-']/following-sibling::label/i[@class='fleft naukicon naukicon-checkbox']\")\n",
    "\n",
    "WebDriverWait(driver, 10).until(expected_conditions.visibility_of_element_located((By.XPATH, \"//input[@id='chk-3-6 Lakhs-ctcFilter-']/following-sibling::label/i[@class='fleft naukicon naukicon-checkbox']\")))\n",
    "\n",
    "#driver.execute_script(\"return arguments[0].scrollIntoView(true);\", filter_salary)\n",
    "#time.sleep(10)\n",
    "#filter_salary.click()\n",
    "\n",
    "#filter_location=driver.find_element_by_xpath(\"//span[contains(@class, 'fw500') and text() = 'Location']/parent::div/following-sibling::div//a\")\n",
    "#filter_location.click()\n",
    "#filter_loction_dncr=driver.find_element_by_xpath(\"//div[@id='tooltip']//div//div//label//p//span[contains(text(),'Delhi / NCR')]\")\n",
    "#filter_loction_dncr.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e365e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#//span[contains(@class, 'fw500') and text() = 'Location']/parent::div/following-sibling::div//a\n",
    "                \n",
    "#//div[@id='tooltip']//div//div//label//p//span[contains(text(),'Delhi / NCR')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4b4626",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "<br>The attributes which you have to scrape is ticked marked in the below image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0ebe9d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Names</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹614</td>\n",
       "      <td>79% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>UV Protection, Riding Glasses, Others Aviator,...</td>\n",
       "      <td>₹167</td>\n",
       "      <td>76% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>84% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹709</td>\n",
       "      <td>21% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹202</td>\n",
       "      <td>92% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>Gradient, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹376</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Round Sunglasses (Free Size)</td>\n",
       "      <td>₹259</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>Others Wayfarer, Retro Square Sunglasses (50)</td>\n",
       "      <td>₹189</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>New Specs</td>\n",
       "      <td>Mirrored, UV Protection, Riding Glasses, Other...</td>\n",
       "      <td>₹233</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>UV Protection Cat-eye Sunglasses (54)</td>\n",
       "      <td>₹599</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand Names                               Product Descriptions Prices  \\\n",
       "0     Singco India  Gradient, Toughened Glass Lens, UV Protection ...   ₹614   \n",
       "1     Singco India  UV Protection, Riding Glasses, Others Aviator,...   ₹167   \n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (50)   ₹199   \n",
       "3         Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   ₹709   \n",
       "4        New Specs   UV Protection Rectangular Sunglasses (Free Size)   ₹202   \n",
       "..             ...                                                ...    ...   \n",
       "95  ROZZETTA CRAFT  Gradient, UV Protection Round Sunglasses (Free...   ₹376   \n",
       "96  kingsunglasses         UV Protection Round Sunglasses (Free Size)   ₹259   \n",
       "97            SRPM      Others Wayfarer, Retro Square Sunglasses (50)   ₹189   \n",
       "98       New Specs  Mirrored, UV Protection, Riding Glasses, Other...   ₹233   \n",
       "99   VINCENT CHASE              UV Protection Cat-eye Sunglasses (54)   ₹599   \n",
       "\n",
       "   Discounts  \n",
       "0    79% off  \n",
       "1    76% off  \n",
       "2    84% off  \n",
       "3    21% off  \n",
       "4    92% off  \n",
       "..       ...  \n",
       "95   81% off  \n",
       "96   83% off  \n",
       "97   81% off  \n",
       "98   85% off  \n",
       "99   70% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "WebDriverWait(driver,10).until(expected_conditions.visibility_of_element_located((By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\"))).click()\n",
    "\n",
    "f_search_field=driver.find_element_by_name(\"q\")\n",
    "f_search_field.send_keys(\"sunglasses\")\n",
    "f_search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "f_search_button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "brand_names=[]\n",
    "product_descriptions=[]\n",
    "prices=[]\n",
    "discounts=[]\n",
    "\n",
    "def data_list(lists, xpath):\n",
    "    tags = driver.find_elements_by_xpath(xpath)\n",
    "    for i in tags:\n",
    "        lists.append(i.text)\n",
    "    return lists\n",
    "\n",
    "brand_name_xpath=\"//div[@class='_2WkVRV']\"\n",
    "product_description_xpath=\"//a[@class='IRpwTa']\"\n",
    "price_xpath=\"//div[@class='_30jeq3']\"\n",
    "discount_xpath=\"//div[@class='_3Ay6Sb']/span\"\n",
    "\n",
    "data_list(brand_names,brand_name_xpath)\n",
    "data_list(product_descriptions,product_description_xpath)\n",
    "data_list(prices,price_xpath)\n",
    "data_list(discounts,discount_xpath)\n",
    "\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(brand_names,brand_name_xpath)\n",
    "data_list(product_descriptions,product_description_xpath)\n",
    "data_list(prices,price_xpath)\n",
    "data_list(discounts,discount_xpath)\n",
    "\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(brand_names,brand_name_xpath)\n",
    "data_list(product_descriptions,product_description_xpath)\n",
    "data_list(prices,price_xpath)\n",
    "data_list(discounts,discount_xpath)\n",
    "\n",
    "\n",
    "f_df = pd.DataFrame({\"Brand Names\":brand_names[:100],\n",
    "                     \"Product Descriptions\":product_descriptions[:100],\n",
    "                     \"Prices\":prices[:100],\n",
    "                     \"Discounts\":discounts[:100]\n",
    "                    })\n",
    "f_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c20172",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace.\n",
    "When you will open the above link you will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0d8046a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>This is my first iOS phone. I am very happy wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Great product</td>\n",
       "      <td>Amazing Powerful and Durable Gadget.\\n\\nI’m am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>i11 is worthy to buy, too much happy with the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5            Fabulous!   \n",
       "..    ...                  ...   \n",
       "95      5    Worth every penny   \n",
       "96      5        Great product   \n",
       "97      4          Good choice   \n",
       "98      5   Highly recommended   \n",
       "99      5    Worth every penny   \n",
       "\n",
       "                                          Full Review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   This is my first iOS phone. I am very happy wi...  \n",
       "..                                                ...  \n",
       "95  Previously I was using one plus 3t it was a gr...  \n",
       "96  Amazing Powerful and Durable Gadget.\\n\\nI’m am...  \n",
       "97  So far it’s been an AMAZING experience coming ...  \n",
       "98  What a camera .....just awesome ..you can feel...  \n",
       "99  i11 is worthy to buy, too much happy with the ...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.get(\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes- earpods-power- adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKC TSVZAXUHGREPBFGI&marketplace\")\n",
    "\n",
    "all_review_button=driver.find_element_by_xpath(\"//div[@class='_3UAT2v _16PBlm']/span\")\n",
    "all_review_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "def data_list(lists, xpath):\n",
    "    tags = driver.find_elements_by_xpath(xpath)\n",
    "    for i in tags:\n",
    "        lists.append(i.text)\n",
    "    return lists\n",
    "\n",
    "rating_list=[]\n",
    "review_summary_list=[]\n",
    "full_review_lits=[]\n",
    "\n",
    "rating_xpath=\"//div[@class='_3LWZlK _1BLPMq']\"\n",
    "review_summary_xpath=\"//p[@class='_2-N8zT']\"\n",
    "full_review_xpath=\"//div[@class='t-ZTKy']/div/div\"\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(rating_list,rating_xpath)\n",
    "data_list(review_summary_list,review_summary_xpath)\n",
    "data_list(full_review_lits,full_review_xpath)\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "f_snkr_df = pd.DataFrame({\"Rating\":rating_list[:100],\n",
    "                     \"Review Summary\":review_summary_list[:100],\n",
    "                     \"Full Review\":full_review_lits[:100]\n",
    "                    })\n",
    "f_snkr_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083300f",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com andsearch for “sneakers” in the search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "36686206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Names</th>\n",
       "      <th>Product Descriptions</th>\n",
       "      <th>Prices</th>\n",
       "      <th>Discounts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Super Stylish &amp; Trendy Combo Pack of 02 Pairs ...</td>\n",
       "      <td>₹469</td>\n",
       "      <td>70% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KWIK FIT</td>\n",
       "      <td>Kwik FIT casual sneaker shoes and partywear sh...</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹374</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASTEROID</td>\n",
       "      <td>Original Luxury Branded Fashionable Men's Casu...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>78% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Sneakers Shoes Sneakers For Men</td>\n",
       "      <td>₹209</td>\n",
       "      <td>83% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Rzisbo</td>\n",
       "      <td>Casuals, Canvas, Partywear Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>50% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Men 5014 Latest Collection Stylish Casual Spor...</td>\n",
       "      <td>₹424</td>\n",
       "      <td>57% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹249</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Perfect Combo Pack of 03 Pairs Casual Sneakers...</td>\n",
       "      <td>₹348</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ZF - ALFIYA</td>\n",
       "      <td>sneaker men red 1258 - 6 Sneakers For Men</td>\n",
       "      <td>₹374</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Brand Names                               Product Descriptions Prices  \\\n",
       "0        Chevit  Super Stylish & Trendy Combo Pack of 02 Pairs ...   ₹469   \n",
       "1      KWIK FIT  Kwik FIT casual sneaker shoes and partywear sh...   ₹349   \n",
       "2      Magnolia                                   Sneakers For Men   ₹374   \n",
       "3      ASTEROID  Original Luxury Branded Fashionable Men's Casu...   ₹424   \n",
       "4        BRUTON      Modern Trendy Sneakers Shoes Sneakers For Men   ₹209   \n",
       "..          ...                                                ...    ...   \n",
       "95       Rzisbo        Casuals, Canvas, Partywear Sneakers For Men   ₹499   \n",
       "96       Labbin  Men 5014 Latest Collection Stylish Casual Spor...   ₹424   \n",
       "97   D-SNEAKERZ                                   Sneakers For Men   ₹249   \n",
       "98    SCATCHITE  Perfect Combo Pack of 03 Pairs Casual Sneakers...   ₹348   \n",
       "99  ZF - ALFIYA          sneaker men red 1258 - 6 Sneakers For Men   ₹374   \n",
       "\n",
       "   Discounts  \n",
       "0    70% off  \n",
       "1    82% off  \n",
       "2    62% off  \n",
       "3    78% off  \n",
       "4    83% off  \n",
       "..       ...  \n",
       "95   50% off  \n",
       "96   57% off  \n",
       "97   62% off  \n",
       "98   65% off  \n",
       "99   62% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "time.sleep(2)\n",
    "driver.get(\"https://www.flipkart.com/\")\n",
    "\n",
    "WebDriverWait(driver,10).until(expected_conditions.visibility_of_element_located((By.XPATH,\"//button[@class='_2KpZ6l _2doB4z']\"))).click()\n",
    "\n",
    "f_search_field=driver.find_element_by_name(\"q\")\n",
    "f_search_field.send_keys(\"sneakers\")\n",
    "f_search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "f_search_button.click()\n",
    "time.sleep(1)\n",
    "\n",
    "brand_names=[]\n",
    "product_descriptions=[]\n",
    "prices=[]\n",
    "discounts=[]\n",
    "\n",
    "def data_list(lists, xpath):\n",
    "    tags = driver.find_elements_by_xpath(xpath)\n",
    "    for i in tags:\n",
    "        lists.append(i.text)\n",
    "    return lists\n",
    "\n",
    "brand_name_xpath=\"//div[@class='_2WkVRV']\"\n",
    "product_description_xpath=\"//a[@class='IRpwTa']\"\n",
    "price_xpath=\"//div[@class='_30jeq3']\"\n",
    "discount_xpath=\"//div[@class='_3Ay6Sb']/span\"\n",
    "\n",
    "data_list(brand_names,brand_name_xpath)\n",
    "data_list(product_descriptions,product_description_xpath)\n",
    "data_list(prices,price_xpath)\n",
    "data_list(discounts,discount_xpath)\n",
    "\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(brand_names,brand_name_xpath)\n",
    "data_list(product_descriptions,product_description_xpath)\n",
    "data_list(prices,price_xpath)\n",
    "data_list(discounts,discount_xpath)\n",
    "\n",
    "click_next=driver.find_element_by_xpath(\"//a[@class='_1LKTO3']/span\")\n",
    "click_next.click()\n",
    "time.sleep(3)\n",
    "\n",
    "data_list(brand_names,brand_name_xpath)\n",
    "data_list(product_descriptions,product_description_xpath)\n",
    "data_list(prices,price_xpath)\n",
    "data_list(discounts,discount_xpath)\n",
    "\n",
    "\n",
    "f_df = pd.DataFrame({\"Brand Names\":brand_names[:100],\n",
    "                     \"Product Descriptions\":product_descriptions[:100],\n",
    "                     \"Prices\":prices[:100],\n",
    "                     \"Discounts\":discounts[:100]\n",
    "                    })\n",
    "f_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f61fd8",
   "metadata": {},
   "source": [
    "### Q7: Go to the link - https://www.myntra.com/shoes Set Price filter to “Rs. 7149 to Rs. 14099 ” , Color filter to “Black”, as shown inthe below image. And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe description, price of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c62f296e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 11199Rs. 15999(30% OFF)</td>\n",
       "      <td>Men Leather Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 9099Rs. 12999(30% OFF)</td>\n",
       "      <td>Men Leather Driving Shoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Rs. 8295</td>\n",
       "      <td>Men JORDAN ONE Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALDO</td>\n",
       "      <td>Rs. 9099Rs. 12999(30% OFF)</td>\n",
       "      <td>Men Printed Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Rs. 7649Rs. 8999(15% OFF)</td>\n",
       "      <td>Men Max Cushioning Running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Rs. 12990</td>\n",
       "      <td>Men Suede Loafers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROSSO BRUNELLO</td>\n",
       "      <td>Rs. 10999</td>\n",
       "      <td>Men Leather Formal Oxfords</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Heel &amp; Buckle London</td>\n",
       "      <td>Rs. 13990</td>\n",
       "      <td>Men Leather Sneakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 11999</td>\n",
       "      <td>Women Open Toe Flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Cole Haan</td>\n",
       "      <td>Rs. 12999</td>\n",
       "      <td>Women Sneakers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand Name                        Price  \\\n",
       "0                   ALDO  Rs. 11199Rs. 15999(30% OFF)   \n",
       "1                   ALDO   Rs. 9099Rs. 12999(30% OFF)   \n",
       "2                   Nike                     Rs. 8295   \n",
       "3                   ALDO   Rs. 9099Rs. 12999(30% OFF)   \n",
       "4               Skechers    Rs. 7649Rs. 8999(15% OFF)   \n",
       "..                   ...                          ...   \n",
       "95  Heel & Buckle London                    Rs. 12990   \n",
       "96        ROSSO BRUNELLO                    Rs. 10999   \n",
       "97  Heel & Buckle London                    Rs. 13990   \n",
       "98             Cole Haan                    Rs. 11999   \n",
       "99             Cole Haan                    Rs. 12999   \n",
       "\n",
       "                   Description  \n",
       "0          Men Leather Loafers  \n",
       "1    Men Leather Driving Shoes  \n",
       "2    Men JORDAN ONE Basketball  \n",
       "3         Men Printed Sneakers  \n",
       "4   Men Max Cushioning Running  \n",
       "..                         ...  \n",
       "95           Men Suede Loafers  \n",
       "96  Men Leather Formal Oxfords  \n",
       "97        Men Leather Sneakers  \n",
       "98        Women Open Toe Flats  \n",
       "99              Women Sneakers  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.myntra.com/shoes\")\n",
    "time.sleep(1)\n",
    "\n",
    "price_filter=driver.find_element_by_xpath(\"//label[contains(@class,'common-customCheckbox vertical-filters-label') and text()='Rs. 7187 to Rs. 14125']\")\n",
    "price_filter.click()\n",
    "time.sleep(1)\n",
    "color_filter=driver.find_element_by_xpath(\"//span[contains(@class,'colour-label colour-colorDisplay') and @data-colorhex='black']\")\n",
    "color_filter.click()\n",
    "time.sleep(1)\n",
    "def data_list(lists, xpath):\n",
    "    tags = driver.find_elements_by_xpath(xpath)\n",
    "    for i in tags:\n",
    "        lists.append(i.text)\n",
    "    return lists\n",
    "\n",
    "brand=[]\n",
    "product_desc=[]\n",
    "m_price=[]\n",
    "\n",
    "brand_xpath=\"//h3[@class='product-brand']\"\n",
    "product_desc_xpath=\"//h4[@class='product-product']\"\n",
    "m_price_xpath=\"//div[@class='product-price']\"\n",
    "\n",
    "data_list(brand,brand_xpath)\n",
    "data_list(product_desc,product_desc_xpath)\n",
    "data_list(m_price,m_price_xpath)\n",
    "\n",
    "click_next=driver.find_element_by_xpath(\"//span[@class='pagination-arrowRight']\")\n",
    "click_next.click()\n",
    "time.sleep(1)\n",
    "data_list(brand,brand_xpath)\n",
    "data_list(product_desc,product_desc_xpath)\n",
    "data_list(m_price,m_price_xpath)\n",
    "\n",
    "Shoes = pd.DataFrame({})\n",
    "Shoes['Brand Name'] = brand\n",
    "Shoes['Price'] = m_price\n",
    "Shoes['Description'] = product_desc\n",
    "Shoes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37452d3f",
   "metadata": {},
   "source": [
    "### Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” and “Intel Core i9”\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "6bb372a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Price on Amazon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...</td>\n",
       "      <td>1,29,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...</td>\n",
       "      <td>1,20,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>57,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....</td>\n",
       "      <td>86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...</td>\n",
       "      <td>81,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...</td>\n",
       "      <td>1,05,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LG Gram Intel Evo 11th Gen Core i7 17 inches U...</td>\n",
       "      <td>94,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LG Gram 14 inches Ultra-Light Intel Evo 11th G...</td>\n",
       "      <td>88,499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand Name Price on Amazon\n",
       "0  Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...        1,29,990\n",
       "1  Samsung Galaxy Book2 Pro 360 Intel 12th Gen i7...        1,20,990\n",
       "2  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...          57,490\n",
       "3  HP Pavilion 14, 11th Gen Intel Core i7-16GB RA...          86,990\n",
       "4  Lenovo ThinkBook 15 Intel 11th Gen Core i7 15....          86,990\n",
       "5  Lenovo IdeaPad Flex 5 11th Gen Intel Core i7 1...          81,990\n",
       "6  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...          89,990\n",
       "7  Samsung Galaxy Book2 360 Intel 12th Gen i7 Evo...        1,05,990\n",
       "8  LG Gram Intel Evo 11th Gen Core i7 17 inches U...          94,999\n",
       "9  LG Gram 14 inches Ultra-Light Intel Evo 11th G...          88,499"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.amazon.in/\")\n",
    "time.sleep(1)\n",
    "\n",
    "search_box=driver.find_element_by_id(\"twotabsearchtextbox\")\n",
    "search_box.send_keys(\"Laptop\")\n",
    "\n",
    "a_search=driver.find_element_by_id(\"nav-search-submit-button\")\n",
    "a_search.click()\n",
    "time.sleep(1)\n",
    "\n",
    "i7=driver.find_element_by_xpath(\"//*[@id='p_n_feature_thirteen_browse-bin/12598163031']/span/a/div\")\n",
    "i7.click()\n",
    "time.sleep(1)\n",
    "#i9=driver.find_element_by_xpath(\"//li[@id='p_n_feature_thirteen_browse-bin/16757432031']/span/a\")\n",
    "#i9.click()\n",
    "#time.sleep(1)\n",
    "titles = driver.find_elements_by_xpath(\"//h2[@class='a-size-mini a-spacing-none a-color-base s-line-clamp-2']\")\n",
    "laptop = []\n",
    "for i in titles:\n",
    "    laptop.append(i.text)\n",
    "    \n",
    "prc = driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "price = []\n",
    "for i in prc:\n",
    "    price.append(i.text)\n",
    "    \n",
    "Laptops = pd.DataFrame({})\n",
    "Laptops['Brand Name'] = laptop[:10]\n",
    "Laptops['Price on Amazon'] = price[:10]\n",
    "Laptops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601d689",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter “Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter “Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "71bc8334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Posted days ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>4.1</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tech Mahindra Ltd</td>\n",
       "      <td>4.1</td>\n",
       "      <td>14d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GENPACT India Private Limited</td>\n",
       "      <td>3.7</td>\n",
       "      <td>17d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HCL Technologies</td>\n",
       "      <td>4.0</td>\n",
       "      <td>21d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum Global Solutions (India) Private Limited</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1mon ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Newgen Software Technologies Ltd.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JK Technosoft Ltd</td>\n",
       "      <td>3.5</td>\n",
       "      <td>10d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pitney Bowes India Pvt Ltd</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1mon ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Microsoft India (R and D) Pvt Ltd</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1mon ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paytm Payments Bank Limited</td>\n",
       "      <td>4.2</td>\n",
       "      <td>20d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Company Rating Posted days ago\n",
       "0  Optum Global Solutions (India) Private Limited    4.1         15d ago\n",
       "1                               Tech Mahindra Ltd    4.1         14d ago\n",
       "2                   GENPACT India Private Limited    3.7         17d ago\n",
       "3                                HCL Technologies    4.0         21d ago\n",
       "4  Optum Global Solutions (India) Private Limited    3.8        1mon ago\n",
       "5               Newgen Software Technologies Ltd.    4.1          1d ago\n",
       "6                               JK Technosoft Ltd    3.5         10d ago\n",
       "7                      Pitney Bowes India Pvt Ltd    3.6        1mon ago\n",
       "8               Microsoft India (R and D) Pvt Ltd    4.2        1mon ago\n",
       "9                     Paytm Payments Bank Limited    4.2         20d ago"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "time.sleep(1)\n",
    "\n",
    "click_on_job=driver.find_element_by_xpath(\"//a[@class='link jobs']\")\n",
    "click_on_job.click()\n",
    "time.sleep(2)\n",
    "\n",
    "enter_job=driver.find_element_by_xpath(\"//input[@class='input tt-input']\")\n",
    "enter_job.send_keys(\"Data Scientist\")\n",
    "enter_job.send_keys(Keys.ENTER)\n",
    "time.sleep(3)\n",
    "driver.refresh()\n",
    "time.sleep(3)\n",
    "loc_drpdown=driver.find_element_by_xpath(\"//div[contains(@title,'Location')]/p\")\n",
    "loc_drpdown.click()\n",
    "\n",
    "loc_search_box=driver.find_element_by_xpath(\"//div[@class='searchbox']/input[@placeholder='Search locations']\")\n",
    "loc_search_box.send_keys(\"Noida\")\n",
    "\n",
    "select_noida=driver.find_element_by_xpath(\"//label[@for='location_Noida']\")\n",
    "select_noida.click()\n",
    "time.sleep(2)\n",
    "\n",
    "def data_list(lists, xpath):\n",
    "    tags = driver.find_elements_by_xpath(xpath)\n",
    "    for i in tags:\n",
    "        lists.append(i.text)\n",
    "    return lists\n",
    "\n",
    "company_list=[]\n",
    "company_list_xpath=\"//p[@class='company body-medium']\"\n",
    "\n",
    "rating_list=[]\n",
    "rating_list_xpath=\"//div[@class='rating-wrapper']/a[1]/span\"\n",
    "\n",
    "days_ago_list=[]\n",
    "days_ago_list_xpath=\"//div[@class='other-info']//span[1]\"\n",
    "\n",
    "data_list(company_list,company_list_xpath)\n",
    "data_list(rating_list,rating_list_xpath)\n",
    "data_list(days_ago_list,days_ago_list_xpath)\n",
    "\n",
    "job_df=pd.DataFrame({})\n",
    "job_df[\"Company\"]=company_list[:10]\n",
    "job_df[\"Rating\"]=rating_list[:10]\n",
    "job_df[\"Posted days ago\"]=days_ago_list[:10]\n",
    "\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a7814",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "15176831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Number of Salaries</th>\n",
       "      <th>Minimum Salary</th>\n",
       "      <th>Mean Salary</th>\n",
       "      <th>Maximum Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 11 salaries</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 29.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 31 salaries</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "      <td>₹ 25.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Reliance Jio</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>₹ 5.6L</td>\n",
       "      <td>₹ 18.9L</td>\n",
       "      <td>₹ 26.2L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 15 salaries</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 28 salaries</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.4L</td>\n",
       "      <td>₹ 22.4L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 81 salaries</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 15.1L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 46 salaries</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 14.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 53 salaries</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Company Name    Number of Salaries Minimum Salary Mean Salary  \\\n",
       "0                   Walmart  based on 11 salaries        ₹ 25.0L     ₹ 29.7L   \n",
       "1                  Ab Inbev  based on 31 salaries        ₹ 15.0L     ₹ 20.5L   \n",
       "2              Reliance Jio  based on 10 salaries         ₹ 5.6L     ₹ 18.9L   \n",
       "3                        ZS  based on 15 salaries         ₹ 9.8L     ₹ 15.9L   \n",
       "4                     Optum  based on 28 salaries        ₹ 11.0L     ₹ 15.4L   \n",
       "5         Fractal Analytics  based on 81 salaries         ₹ 9.5L     ₹ 15.1L   \n",
       "6           Tiger Analytics  based on 46 salaries         ₹ 9.0L     ₹ 14.8L   \n",
       "7              UnitedHealth  based on 53 salaries         ₹ 8.3L     ₹ 14.0L   \n",
       "8                   Verizon  based on 14 salaries        ₹ 10.0L     ₹ 12.7L   \n",
       "9  Ganit Business Solutions  based on 13 salaries         ₹ 8.5L     ₹ 12.4L   \n",
       "\n",
       "  Maximum Salary  \n",
       "0        ₹ 35.0L  \n",
       "1        ₹ 25.5L  \n",
       "2        ₹ 26.2L  \n",
       "3        ₹ 20.0L  \n",
       "4        ₹ 22.4L  \n",
       "5        ₹ 22.0L  \n",
       "6        ₹ 20.0L  \n",
       "7        ₹ 20.5L  \n",
       "8        ₹ 21.0L  \n",
       "9        ₹ 15.0L  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver = webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()\n",
    "driver.get(\"https://www.ambitionbox.com/\")\n",
    "time.sleep(1)\n",
    "\n",
    "click_on_salary=driver.find_element_by_xpath(\"//a[@class='link salaries']\")\n",
    "click_on_salary.click()\n",
    "time.sleep(2)\n",
    "\n",
    "enter_job=driver.find_element_by_xpath(\"//input[@class='tt-input']\")\n",
    "enter_job.send_keys(\"Data Scientist\")\n",
    "time.sleep(2)\n",
    "click_on_ds=driver.find_elements_by_xpath(\"//p[contains(text(),'Data Scientist')]\")\n",
    "click_on_ds[0].click()\n",
    "time.sleep(2)\n",
    "def data_list(lists, xpath):\n",
    "    tags = driver.find_elements_by_xpath(xpath)\n",
    "    for i in tags:\n",
    "        lists.append(i.text)\n",
    "    return lists\n",
    "\n",
    "c_name=[]\n",
    "c_name_xpath=\"//div[@class='company-info']/div[@class='name']/a\"\n",
    "no_of_salaries=[]\n",
    "no_of_salaries_xpath=\"//div[@class='company-info']/div[@class='name']/span\"\n",
    "min_salary=[]\n",
    "min_salary_xpath=\"//div[@class='salary-values']/div[1]\"\n",
    "max_salary=[]\n",
    "max_salary_xpath=\"//div[@class='salary-values']/div[2]\"\n",
    "mean_salary=[]\n",
    "mean_salary_xpath=\"//p[@class='averageCtc']\"\n",
    "\n",
    "data_list(c_name,c_name_xpath)\n",
    "time.sleep(2)\n",
    "data_list(no_of_salaries,no_of_salaries_xpath)\n",
    "time.sleep(2)\n",
    "data_list(min_salary,min_salary_xpath)\n",
    "time.sleep(2)\n",
    "data_list(max_salary,max_salary_xpath)\n",
    "time.sleep(2)\n",
    "data_list(mean_salary,mean_salary_xpath)\n",
    "time.sleep(2)\n",
    "\n",
    "a_data_df= pd.DataFrame({\n",
    "    \"Company Name\":c_name[:10],\n",
    "    \"Number of Salaries\":no_of_salaries[:10],\n",
    "    \"Minimum Salary\":min_salary[:10],\n",
    "    \"Mean Salary\":mean_salary[:10],\n",
    "    \"Maximum Salary\":max_salary[:10]\n",
    "})\n",
    "a_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d0032b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0de0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5583c79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb959260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2e026848",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1f7c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
